# Hybrid Music Clustering using Variational Autoencoders

Unsupervised learning pipeline for clustering hybrid language (English/Bangla) music tracks using Variational Autoencoders (VAE) with multi-modal features (audio + lyrics + genre).

## ğŸ“‹ Project Overview

This project implements VAE-based clustering for music analysis with:
- **Multi-modal feature extraction**: Audio (MFCC/Mel-spectrogram), Lyrics (SBERT embeddings), Genre labels
- **Multiple VAE architectures**: MLP-VAE, ConvVAE, Conditional VAE (CVAE), Beta-VAE
- **Clustering algorithms**: K-Means, Agglomerative Clustering, DBSCAN
- **Comprehensive evaluation**: Silhouette Score, ARI, NMI, Cluster Purity, Davies-Bouldin Index, Calinski-Harabasz Index

## ğŸ—ï¸ Repository Structure

```
project/
â”‚
â”œâ”€â”€ data/ 
|   |â”€â”€ dataset_link
â”‚       â”œâ”€â”€ audio/               â† Raw audio files
â”‚       â”œâ”€â”€ lyrics/              â† Raw lyrics data
â”‚       â”œâ”€â”€ Audio_Features/      â† Extracted features from audio (e.g., MFCC, spectrograms)
â”‚       â”œâ”€â”€ Lyrics_Preprocessed/ â† Preprocessed lyrics (e.g., tokenized)
â”‚       â”œâ”€â”€ MultiModal/          â† Multimodal data (audio + lyrics)
â”‚       â”œâ”€â”€ audio_metadata/      â† Metadata for audio files
â”‚       â”œâ”€â”€ lyrics_metadata/     â† Metadata for lyrics
â”‚       â”œâ”€â”€ genre_label_classes/ â† Genre label classes
â”‚       â”œâ”€â”€ genre_processed/     â† Processed genre data (e.g., encoded)
â”‚       â””â”€â”€ genre/               â† Raw genre data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ all_in_one_scattered     â† Integrated notebook for various tasks
â”‚   â”œâ”€â”€ Create_Genre            â† Genre creation and modeling notebook
â”‚   â”œâ”€â”€ exploratory             â† Exploratory data analysis (EDA) notebook
â”‚   â””â”€â”€ generate_eda_visualizations â† Visualizations for EDA
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ eda/                    â† Results from exploratory data analysis
â”‚   â”œâ”€â”€ EasyTask/               â† Results for easy tasks
â”‚   â”œâ”€â”€ MediumTask/             â† Results for medium tasks
â”‚   â”œâ”€â”€ MediumTask_WithARI/     â† Results for medium tasks with ARI 
â”‚   â”œâ”€â”€ HardTask/               â† Results for hard tasks
â”‚   â””â”€â”€ HardTask_CVAE/          â† Results for hard tasks using CVAE 
â”‚
â””â”€â”€ src/                         â† Source code and project files
    â”œâ”€â”€ __init__.py             â† Marks this folder as a Python package
    â”œâ”€â”€ vae.py                  â† Variational Autoencoder model code
    â”œâ”€â”€ dataset.py              â† Dataset handling code
    â”œâ”€â”€ clustering.py           â† Clustering code (e.g., for genre or features)
    â”œâ”€â”€ evaluation.py           â† Model evaluation code
    â”œâ”€â”€ visualization.py        â† Visualization code
â”œâ”€â”€ README.md               â† Project overview 
â””â”€â”€ requirements.txt        â† List of project dependencies

```

## ğŸš€ Setup Instructions

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended for faster training)

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd <project-directory>
```

2. Create a virtual environment:
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

### Data Preparation

1. Place your audio files in `Audio/` directory
2. Place lyrics files in `Lyrics/` directory
3. Place genre metadata in `genre.csv`

## ğŸ“Š Usage

### Preprocessing

Run the preprocessing cells in the notebook to:
1. Process genre labels and create multi-hot encodings
2. Extract audio features (MFCC, Mel-spectrograms)
3. Process and embed lyrics using SBERT
4. Align multi-modal data across track IDs

### Training

The project includes three difficulty levels:

#### Easy Task
- Basic MLP-VAE with mean+std audio features
- K-Means clustering
- Baseline: PCA + K-Means
- Metrics: Silhouette Score, Calinski-Harabasz Index

#### Medium Task
- ConvVAE for 2D audio features
- Hybrid features: Audio latent + Lyrics embeddings
- Multiple clustering algorithms (KMeans, Agglomerative, DBSCAN)
- Systematic hyperparameter tuning
- Metrics: Silhouette, Davies-Bouldin, ARI

#### Hard Task
- Conditional VAE (CVAE) with genre conditioning
- Beta-VAE for disentangled representations
- Multi-modal clustering (Audio + Lyrics + Genre)
- Complete metrics suite: Silhouette, ARI, NMI, Purity
- Enhanced visualizations

### Running Experiments

```python
# Import modules
from src.vae import ConvVAE, MultiModalVAE
from src.dataset import align_multimodal_data
from src.clustering import run_all_clusterers
from src.evaluation import compute_all_metrics

# See notebooks/exploratory.ipynb for complete examples
```

## ğŸ“ˆ Results

Results are saved in the `Results/` directory:
- **EasyTask/**: Basic VAE results, latent features, cluster assignments
- **MediumTask_WithARI/**: ConvVAE results with ARI computation
- **HardTask_CVAE/**: CVAE/Beta-VAE results with complete metrics

Key outputs:
- `clustering_results.csv`: Comparison of all methods
- `cluster_assignments.csv`: Track-level cluster labels
- `vae_training_history.csv`: Training loss curves
- Visualization plots in respective directories

## ğŸ“Š Evaluation Metrics

| Metric | Description | Range | Better |
|--------|-------------|-------|---------|
| Silhouette Score | Cluster cohesion vs separation | [-1, 1] | Higher |
| Davies-Bouldin | Average cluster similarity | [0, âˆ) | Lower |
| Calinski-Harabasz | Between/within variance ratio | [0, âˆ) | Higher |
| ARI | Agreement with true labels | [-1, 1] | Higher |
| NMI | Mutual information with labels | [0, 1] | Higher |
| Purity | Dominant class in cluster | [0, 1] | Higher |

## ğŸ”§ Configuration

Key hyperparameters can be adjusted:
- `LATENT_DIM`: VAE latent dimension (16-128)
- `BETA`: KL divergence weight for Beta-VAE (0.1-8.0)
- `N_CLUSTERS`: Number of clusters (6-20)
- `EPOCHS`: Training epochs (20-60)
- `BATCH_SIZE`: Mini-batch size (16-64)

## ğŸ“ Citation

If you use this code, please cite:
```
[Your Project Title]
[Your Name/Team]
[Year]
```

## ğŸ“„ License

[Your License Here]

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact

For questions or issues, please open an issue on GitHub or contact [your-email].

## ğŸ™ Acknowledgments

- SBERT for multilingual text embeddings
- PyTorch for deep learning framework
- Scikit-learn for clustering and evaluation
